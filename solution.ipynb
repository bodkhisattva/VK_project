{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08004cf-c06d-4b6e-854a-8ac2287e4ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\dfu\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dfu\\anaconda3\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\dfu\\anaconda3\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\dfu\\anaconda3\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\dfu\\anaconda3\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dfu\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2 tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02486bef-2096-4783-b8ea-4f9146df1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np, pandas as pd  # заранее проведем все необходимые импорты\n",
    "from tqdm import tqdm\n",
    "import pymorphy2\n",
    "from functools import lru_cache\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, confusion_matrix\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b11bdb44-da4d-4fe3-92a9-245d4050d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "\n",
    "train_path = \"data/train(1).csv\"\n",
    "test_path  = \"data/test(1).csv\"\n",
    "data_path  = \"data/data(3).csv\"\n",
    "\n",
    "train = pd.read_csv(train_path, sep=';')\n",
    "test  = pd.read_csv(test_path, sep=';')\n",
    "data  = pd.read_csv(data_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebe44eac-18ec-4609-94ab-5e8ce1c053e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect  # функция, помогающая избежать проблем с модулем getargspec в pymorphy (иногда простое обновление библиотек не помогает)\n",
    "if not hasattr(inspect, 'getargspec'):\n",
    "    from collections import namedtuple\n",
    "    ArgSpec = namedtuple('ArgSpec', 'args varargs keywords defaults')\n",
    "    def getargspec(func):\n",
    "        spec = inspect.getfullargspec(func)\n",
    "        return ArgSpec(spec.args, spec.varargs, spec.varkw, spec.defaults)\n",
    "    inspect.getargspec = getargspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ed91e3a-cd5b-41c5-a095-eb68b31b1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:03<00:00, 9431.33it/s] \n",
      "100%|██████████| 11087/11087 [00:00<00:00, 15549.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Validation results ===\n",
      "            model  best_thr        F1         P         R  \\\n",
      "0  SGD(mod_h)+Cal  0.105549  0.262744  0.160441  0.723917   \n",
      "1          LogReg  0.134451  0.253032  0.152695  0.736758   \n",
      "2   LinearSVC+Cal  0.093187  0.243697  0.145637  0.744783   \n",
      "\n",
      "                           cm  \\\n",
      "0  [[3017, 2360], [172, 451]]   \n",
      "1  [[2830, 2547], [164, 459]]   \n",
      "2  [[2655, 2722], [159, 464]]   \n",
      "\n",
      "                                               probs  \n",
      "0  [0.06732157909824042, 0.08857046864580445, 0.1...  \n",
      "1  [0.025290563208516605, 0.0413194818116564, 0.0...  \n",
      "2  [0.07881012712245636, 0.07640378773597503, 0.0...  \n",
      "\n",
      " LogReg Confusion:\n",
      " [[2830 2547]\n",
      " [ 164  459]]\n",
      "\n",
      " SVC+Cal Confusion:\n",
      " [[2655 2722]\n",
      " [ 159  464]]\n",
      "\n",
      " SGD+Cal Confusion:\n",
      " [[3017 2360]\n",
      " [ 172  451]]\n",
      "\n",
      "Chosen model: SGD(mod_h)+Cal\n",
      "\n",
      "Сохранение файла с метриками: submission.csv (ID, score)\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "@lru_cache(maxsize=200000)  # используем очистку кэша, так как данных довольно много и они могут долго обрабатываться\n",
    "def lemma(tok: str) -> str:\n",
    "    return morph.parse(tok)[0].normal_form\n",
    "\n",
    "def clean(s: str) -> str: # проведем минимальную предобработку текста: приведем к нижнему регистру, избавимся от пропусков и спецзнаков, проведем лемматизацию\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'https?://\\S+|www\\.\\S+', ' ', s)\n",
    "    s = re.sub(r'[^a-zа-яё0-9?\\!\\s]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def lemmatize(s: str) -> str:\n",
    "    return \" \".join(lemma(t) for t in s.split()) if s else \"\"\n",
    "\n",
    "# объединим данные из train и test по ID с соовтетствующими вопрсоами из data: так мы получим метки классов для train\n",
    "train_full = train.merge(data, on=\"ID\", how=\"left\")   \n",
    "test_full  = test.merge(data,  on=\"ID\", how=\"left\")\n",
    "\n",
    "\n",
    "train_full[\"question_raw\"] = train_full[\"Question\"].fillna(\"\").map(clean)\n",
    "test_full[\"question_raw\"]  = test_full[\"Question\"].fillna(\"\").map(clean)\n",
    "\n",
    "train_full[\"question_lem\"] = train_full[\"question_raw\"].progress_map(lemmatize)\n",
    "test_full[\"question_lem\"]  = test_full[\"question_raw\"].progress_map(lemmatize)\n",
    "\n",
    "X_all_df = train_full[[\"question_lem\",\"question_raw\"]]  # готовые вопросы для обучения алгоритмов\n",
    "y = train_full[\"Answer\"].astype(int).values\n",
    "\n",
    "X_tr_df, X_va_df, y_tr, y_va = train_test_split(\n",
    "    X_all_df, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "tfidf_word = TfidfVectorizer(analyzer='word', ngram_range=(1,2), min_df=2, max_features=150_000) # векторизируем вопросы\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,6), min_df=2, max_features=120_000)\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"w\", tfidf_word, \"question_lem\"),\n",
    "        (\"c\", tfidf_char, \"question_raw\"),\n",
    "    ],\n",
    "    sparse_threshold=1.0\n",
    ")  #используем ColumnTransformer для упрощения работы с разными фичами, чтобы избежать дополнительных циклов и функций\n",
    "\n",
    "X_tr_tfidf = ct.fit_transform(X_tr_df)\n",
    "X_va_tfidf = ct.transform(X_va_df)\n",
    "\n",
    "\n",
    "# добавим мета-фичи: длина вопроса, количество вопросительных знаков, восклицательных знаков, цифр\n",
    "def make_meta(series: pd.Series):\n",
    "    return np.vstack([\n",
    "        series.str.len(),\n",
    "        series.str.count(r'\\?'),\n",
    "        series.str.count(r'!'),\n",
    "        series.str.count(r'\\d'),\n",
    "    ]).T\n",
    "\n",
    "meta_tr = csr_matrix(make_meta(X_tr_df[\"question_raw\"]))\n",
    "meta_va = csr_matrix(make_meta(X_va_df[\"question_raw\"]))\n",
    "\n",
    "X_tr = hstack([X_tr_tfidf, meta_tr], format='csr')  #соединяем все полученные признаки в датасеты\n",
    "X_va = hstack([X_va_tfidf, meta_va], format='csr')\n",
    "\n",
    "\n",
    "# так как у нас явный дисбаланс классов, то необходимо добавить бОльшие веса миноритарному классу\n",
    "n_pos = int((y_tr==1).sum()); n_neg = int((y_tr==0).sum()) # считаем количество объектов мажоританого и миноритарного класса\n",
    "W_pos = (n_neg / max(1, n_pos)) * 1.2 # вес класса номер 1 (миноритарного)\n",
    "W = {0:1.0, 1:W_pos}\n",
    "\n",
    "\n",
    "# функция оценки модели\n",
    "def eval_model(get_proba, Xval, yval):\n",
    "    p = get_proba(Xval)\n",
    "    prec, rec, thr = precision_recall_curve(yval, p)\n",
    "    f1s = 2*prec[1:]*rec[1:] / (prec[1:]+rec[1:]+1e-12)  # выбираем метрику f1, так как она оринетируется на миноритарный класс\n",
    "    i = int(np.nanargmax(f1s))\n",
    "    best_thr, best_f1 = float(thr[i]), float(f1s[i])\n",
    "    yhat = (p >= best_thr).astype(int)\n",
    "    P,R,F1,_ = precision_recall_fscore_support(yval, yhat, average=\"binary\", zero_division=0)\n",
    "    cm = confusion_matrix(yval, yhat)\n",
    "    return dict(best_thr=best_thr, F1=best_f1, P=P, R=R, cm=cm, probs=p)\n",
    "\n",
    "\n",
    "# сами модели\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(C=2.0, solver=\"liblinear\", class_weight=W, max_iter=3000)\n",
    "lr.fit(X_tr, y_tr)\n",
    "res_lr = eval_model(lambda X: lr.predict_proba(X)[:,1], X_va, y_va)\n",
    "\n",
    "# LinearSVC + calibration\n",
    "svc = LinearSVC(class_weight=W, max_iter=5000)\n",
    "svc_cal = CalibratedClassifierCV(svc, method=\"sigmoid\", cv=5)\n",
    "svc_cal.fit(X_tr, y_tr)\n",
    "res_svc = eval_model(lambda X: svc_cal.predict_proba(X)[:,1], X_va, y_va)\n",
    "\n",
    "# SGD + calibration\n",
    "sgd = SGDClassifier(loss=\"modified_huber\", alpha=1e-5, max_iter=120, class_weight=W, tol=1e-4)\n",
    "sgd_cal = CalibratedClassifierCV(sgd, method=\"sigmoid\", cv=5)\n",
    "sgd_cal.fit(X_tr, y_tr)\n",
    "res_sgd = eval_model(lambda X: sgd_cal.predict_proba(X)[:,1], X_va, y_va)\n",
    "\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"model\":\"LogReg\",         **res_lr},\n",
    "    {\"model\":\"LinearSVC+Cal\",  **res_svc},\n",
    "    {\"model\":\"SGD(mod_h)+Cal\", **res_sgd},\n",
    "]).sort_values(\"F1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"=== Validation results ===\")\n",
    "print(summary)\n",
    "for name,res in [(\"LogReg\",res_lr),(\"SVC+Cal\",res_svc),(\"SGD+Cal\",res_sgd)]:\n",
    "    print(\"\\n\",name,\"Confusion:\\n\",res[\"cm\"])\n",
    "\n",
    "\n",
    "# выбираем лучшую модель\n",
    "best_name = summary.loc[0,\"model\"]\n",
    "print(\"\\nChosen model:\", best_name)\n",
    "\n",
    "# переобучаем моделю на всем train и test\n",
    "X_all_tfidf = ct.fit_transform(X_all_df)\n",
    "meta_all    = csr_matrix(make_meta(train_full[\"question_raw\"]))\n",
    "X_all       = hstack([X_all_tfidf, meta_all], format='csr')\n",
    "\n",
    "X_test_df = test_full[[\"question_lem\",\"question_raw\"]]\n",
    "X_test_tfidf = ct.transform(X_test_df)\n",
    "meta_test    = csr_matrix(make_meta(test_full[\"question_raw\"]))\n",
    "X_test       = hstack([X_test_tfidf, meta_test], format='csr')\n",
    "\n",
    "\n",
    "def make_model(name):\n",
    "    if name==\"LogReg\":\n",
    "        m = LogisticRegression(C=2.0, solver=\"liblinear\", class_weight=W, max_iter=3000)\n",
    "        proba = lambda X: m.predict_proba(X)[:,1]\n",
    "    elif name==\"LinearSVC+Cal\":\n",
    "        base = LinearSVC(class_weight=W, max_iter=5000)\n",
    "        m = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5)\n",
    "        proba = lambda X: m.predict_proba(X)[:,1]\n",
    "    else:\n",
    "        base = SGDClassifier(loss=\"modified_huber\", alpha=1e-5, max_iter=120, class_weight=W, tol=1e-4)\n",
    "        m = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5)\n",
    "        proba = lambda X: m.predict_proba(X)[:,1]\n",
    "    return m, proba\n",
    "\n",
    "final_model, proba_fn = make_model(best_name)\n",
    "final_model.fit(X_all, y)\n",
    "\n",
    "# создаем файл submission\n",
    "probs_test = proba_fn(X_test)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"ID\": test_full[\"ID\"],\n",
    "    \"score\": probs_test\n",
    "}).to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\nСохранение файла с метриками: submission.csv (ID, score)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
